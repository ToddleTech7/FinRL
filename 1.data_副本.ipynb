{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl import config_tickers\n",
    "from finrl.config import INDICATORS\n",
    "import optuna\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2025-01-23'\n",
    "TRAIN_END_DATE = '2025-02-13'\n",
    "TRADE_START_DATE = '2025-02-14'\n",
    "TRADE_END_DATE = '2025-03-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "df_aapl_raw = yf.download(tickers = \"aapl\", start=TRAIN_START_DATE, end=TRADE_END_DATE, interval='15m')\n",
    "# end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "# start_date = (datetime.today() - timedelta(days=20)).strftime('%Y-%m-%d')\n",
    "\n",
    "# df_aapl_raw = yf.download(tickers = \"aapl\", start=start_date, end=end_date, interval=\"15m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                           Close        High         Low        Open  \\\n",
      "Ticker                           AAPL        AAPL        AAPL        AAPL   \n",
      "Datetime                                                                    \n",
      "2025-01-23 14:30:00+00:00  224.770004  226.259995  224.500000  224.729996   \n",
      "2025-01-23 14:45:00+00:00  225.164993  225.580002  224.259995  224.774994   \n",
      "2025-01-23 15:00:00+00:00  226.059998  226.100006  224.890305  225.190002   \n",
      "2025-01-23 15:15:00+00:00  225.970001  227.029999  225.845001  226.059998   \n",
      "2025-01-23 15:30:00+00:00  226.169998  226.369995  225.520004  225.964996   \n",
      "\n",
      "Price                       Volume  \n",
      "Ticker                        AAPL  \n",
      "Datetime                            \n",
      "2025-01-23 14:30:00+00:00  6234470  \n",
      "2025-01-23 14:45:00+00:00  2367934  \n",
      "2025-01-23 15:00:00+00:00  2761257  \n",
      "2025-01-23 15:15:00+00:00  2952351  \n",
      "2025-01-23 15:30:00+00:00  1868152  \n"
     ]
    }
   ],
   "source": [
    "print(df_aapl_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['close', 'high', 'low', 'open', 'volume'], dtype='object', name='Price')\n",
      "Price                           close        high         low        open  \\\n",
      "Datetime                                                                    \n",
      "2025-01-23 14:30:00+00:00  224.770004  226.259995  224.500000  224.729996   \n",
      "2025-01-23 14:45:00+00:00  225.164993  225.580002  224.259995  224.774994   \n",
      "2025-01-23 15:00:00+00:00  226.059998  226.100006  224.890305  225.190002   \n",
      "2025-01-23 15:15:00+00:00  225.970001  227.029999  225.845001  226.059998   \n",
      "2025-01-23 15:30:00+00:00  226.169998  226.369995  225.520004  225.964996   \n",
      "\n",
      "Price                       volume  \n",
      "Datetime                            \n",
      "2025-01-23 14:30:00+00:00  6234470  \n",
      "2025-01-23 14:45:00+00:00  2367934  \n",
      "2025-01-23 15:00:00+00:00  2761257  \n",
      "2025-01-23 15:15:00+00:00  2952351  \n",
      "2025-01-23 15:30:00+00:00  1868152  \n"
     ]
    }
   ],
   "source": [
    "# 如果列是 MultiIndex，可以使用 droplevel 来去掉第二层（'AAPL'）\n",
    "if isinstance(df_aapl_raw.columns, pd.MultiIndex):\n",
    "    # 去掉第二层（'AAPL'），只保留第一个级别\n",
    "    df_aapl_raw.columns = df_aapl_raw.columns.droplevel(1)\n",
    "\n",
    "df_aapl_raw.columns = df_aapl_raw.columns.str.lower()\n",
    "# 显示处理后的结果\n",
    "print(df_aapl_raw.columns)\n",
    "print(df_aapl_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Datetime', 'close', 'high', 'low', 'open', 'volume'], dtype='object', name='Price')\n",
      "Index(['date', 'close', 'high', 'low', 'open', 'volume', 'tic', 'day',\n",
      "       'adjcp'],\n",
      "      dtype='object', name='Price')\n"
     ]
    }
   ],
   "source": [
    "df_aapl = df_aapl_raw.reset_index()  # 保留索引\n",
    "print(df_aapl.columns) \n",
    "df_aapl['datetime'] = df_aapl['Datetime']\n",
    "# df_aapl['date'] = df_aapl['Datetime'].dt.date\n",
    "df_aapl['date'] = pd.to_datetime(df_aapl['Datetime'])\n",
    "df_aapl['tic'] = \"aapl\"\n",
    "df_aapl['day'] = df_aapl['Datetime'].dt.dayofweek \n",
    "#remove datetime\n",
    "df_aapl = df_aapl.drop(['Datetime'], axis=1)\n",
    "df_aapl = df_aapl[['date', 'close', 'high', 'low', 'open', 'volume', 'tic', 'day']]\n",
    "if 'adjcp' not in df_aapl.columns:\n",
    "    df_aapl['adjcp'] = df_aapl['close']\n",
    "    # df_aapl['adjhigh'] = df_aapl['high']\n",
    "    # df_aapl['adjlow'] = df_aapl['low']\n",
    "    # df_aapl['adjopen'] = df_aapl['open']\n",
    "print(df_aapl.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "print(df_aapl[\"date\"].dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                      date       close        high         low  \\\n",
      "0     2025-01-23 14:30:00+00:00  224.770004  226.259995  224.500000   \n",
      "1     2025-01-23 14:45:00+00:00  225.164993  225.580002  224.259995   \n",
      "2     2025-01-23 15:00:00+00:00  226.059998  226.100006  224.890305   \n",
      "3     2025-01-23 15:15:00+00:00  225.970001  227.029999  225.845001   \n",
      "4     2025-01-23 15:30:00+00:00  226.169998  226.369995  225.520004   \n",
      "\n",
      "Price        open   volume   tic  day       adjcp  \n",
      "0      224.729996  6234470  aapl    3  224.770004  \n",
      "1      224.774994  2367934  aapl    3  225.164993  \n",
      "2      225.190002  2761257  aapl    3  226.059998  \n",
      "3      226.059998  2952351  aapl    3  225.970001  \n",
      "4      225.964996  1868152  aapl    3  226.169998  \n"
     ]
    }
   ],
   "source": [
    "print(df_aapl.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS_15M = [\n",
    "    \"boll_ub\",\n",
    "    \"boll_lb\",\n",
    "    \"rsi_30\",\n",
    "    \"cci_30\",\n",
    "    \"dx_30\",\n",
    "    \"close_30_sma\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS_15M,\n",
    "                     use_vix=False,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_aapl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that processed['date'] is a datetime column with full timestamp:\n",
    "processed['date'] = pd.to_datetime(processed['date'])\n",
    "\n",
    "# Create a date_range with 5-minute frequency\n",
    "list_dates = pd.date_range(\n",
    "    start=processed['date'].min(), \n",
    "    end=processed['date'].max(), \n",
    "    freq='15min'\n",
    ")\n",
    "\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "combination = list(itertools.product(list_dates, list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"])\n",
    "# Merge on both \"date\" and \"tic\" (here the 'date' in processed has full time info)\n",
    "processed_full = processed_full.merge(processed, on=[\"date\", \"tic\"], how=\"left\")\n",
    "processed_full.sort_values([\"date\", \"tic\"], inplace=True)\n",
    "processed_full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Fill missing values (you can use forward-fill or another method)\n",
    "processed_full = processed_full.ffill()  # or .bfill() if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-23 14:30:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>224.770004</td>\n",
       "      <td>226.259995</td>\n",
       "      <td>224.500000</td>\n",
       "      <td>224.729996</td>\n",
       "      <td>6234470.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>224.770004</td>\n",
       "      <td>225.526098</td>\n",
       "      <td>224.408900</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>224.770004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-23 14:45:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>225.164993</td>\n",
       "      <td>225.580002</td>\n",
       "      <td>224.259995</td>\n",
       "      <td>224.774994</td>\n",
       "      <td>2367934.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>225.164993</td>\n",
       "      <td>225.526098</td>\n",
       "      <td>224.408900</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>224.967499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-23 15:00:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>226.059998</td>\n",
       "      <td>226.100006</td>\n",
       "      <td>224.890305</td>\n",
       "      <td>225.190002</td>\n",
       "      <td>2761257.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>226.059998</td>\n",
       "      <td>226.653566</td>\n",
       "      <td>224.009764</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>39.687424</td>\n",
       "      <td>225.331665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-23 15:15:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>225.970001</td>\n",
       "      <td>227.029999</td>\n",
       "      <td>225.845001</td>\n",
       "      <td>226.059998</td>\n",
       "      <td>2952351.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>225.970001</td>\n",
       "      <td>226.745211</td>\n",
       "      <td>224.237287</td>\n",
       "      <td>93.204041</td>\n",
       "      <td>111.308097</td>\n",
       "      <td>74.173003</td>\n",
       "      <td>225.491249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-23 15:30:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>226.169998</td>\n",
       "      <td>226.369995</td>\n",
       "      <td>225.520004</td>\n",
       "      <td>225.964996</td>\n",
       "      <td>1868152.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>226.169998</td>\n",
       "      <td>226.871135</td>\n",
       "      <td>224.382862</td>\n",
       "      <td>94.122327</td>\n",
       "      <td>59.383228</td>\n",
       "      <td>43.518110</td>\n",
       "      <td>225.626999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-01-24 14:15:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>223.649994</td>\n",
       "      <td>223.649994</td>\n",
       "      <td>222.369995</td>\n",
       "      <td>222.369995</td>\n",
       "      <td>5495496.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>223.649994</td>\n",
       "      <td>225.030627</td>\n",
       "      <td>221.946161</td>\n",
       "      <td>45.555309</td>\n",
       "      <td>-51.733595</td>\n",
       "      <td>18.916673</td>\n",
       "      <td>223.970272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-01-24 14:30:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>225.095001</td>\n",
       "      <td>225.630005</td>\n",
       "      <td>224.330002</td>\n",
       "      <td>224.975006</td>\n",
       "      <td>7878347.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>225.095001</td>\n",
       "      <td>225.067880</td>\n",
       "      <td>221.923409</td>\n",
       "      <td>56.544824</td>\n",
       "      <td>68.170619</td>\n",
       "      <td>26.439006</td>\n",
       "      <td>224.011929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-01-24 14:45:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>224.509995</td>\n",
       "      <td>225.425003</td>\n",
       "      <td>224.309998</td>\n",
       "      <td>225.100006</td>\n",
       "      <td>2143996.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>224.509995</td>\n",
       "      <td>224.908127</td>\n",
       "      <td>222.016660</td>\n",
       "      <td>52.137385</td>\n",
       "      <td>48.290240</td>\n",
       "      <td>25.920321</td>\n",
       "      <td>224.029717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-01-24 15:00:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>223.255005</td>\n",
       "      <td>224.589996</td>\n",
       "      <td>222.899994</td>\n",
       "      <td>224.535004</td>\n",
       "      <td>3135541.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>223.255005</td>\n",
       "      <td>224.777531</td>\n",
       "      <td>222.029759</td>\n",
       "      <td>44.448656</td>\n",
       "      <td>-30.995119</td>\n",
       "      <td>3.810734</td>\n",
       "      <td>224.003003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025-01-24 15:15:00+00:00</td>\n",
       "      <td>aapl</td>\n",
       "      <td>222.729996</td>\n",
       "      <td>223.369995</td>\n",
       "      <td>222.530106</td>\n",
       "      <td>223.259903</td>\n",
       "      <td>2088312.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>222.729996</td>\n",
       "      <td>224.709197</td>\n",
       "      <td>221.967092</td>\n",
       "      <td>41.782129</td>\n",
       "      <td>-77.623543</td>\n",
       "      <td>9.784003</td>\n",
       "      <td>223.960569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date   tic       close        high         low  \\\n",
       "0  2025-01-23 14:30:00+00:00  aapl  224.770004  226.259995  224.500000   \n",
       "1  2025-01-23 14:45:00+00:00  aapl  225.164993  225.580002  224.259995   \n",
       "2  2025-01-23 15:00:00+00:00  aapl  226.059998  226.100006  224.890305   \n",
       "3  2025-01-23 15:15:00+00:00  aapl  225.970001  227.029999  225.845001   \n",
       "4  2025-01-23 15:30:00+00:00  aapl  226.169998  226.369995  225.520004   \n",
       "..                       ...   ...         ...         ...         ...   \n",
       "95 2025-01-24 14:15:00+00:00  aapl  223.649994  223.649994  222.369995   \n",
       "96 2025-01-24 14:30:00+00:00  aapl  225.095001  225.630005  224.330002   \n",
       "97 2025-01-24 14:45:00+00:00  aapl  224.509995  225.425003  224.309998   \n",
       "98 2025-01-24 15:00:00+00:00  aapl  223.255005  224.589996  222.899994   \n",
       "99 2025-01-24 15:15:00+00:00  aapl  222.729996  223.369995  222.530106   \n",
       "\n",
       "          open     volume  day       adjcp     boll_ub     boll_lb  \\\n",
       "0   224.729996  6234470.0  3.0  224.770004  225.526098  224.408900   \n",
       "1   224.774994  2367934.0  3.0  225.164993  225.526098  224.408900   \n",
       "2   225.190002  2761257.0  3.0  226.059998  226.653566  224.009764   \n",
       "3   226.059998  2952351.0  3.0  225.970001  226.745211  224.237287   \n",
       "4   225.964996  1868152.0  3.0  226.169998  226.871135  224.382862   \n",
       "..         ...        ...  ...         ...         ...         ...   \n",
       "95  222.369995  5495496.0  3.0  223.649994  225.030627  221.946161   \n",
       "96  224.975006  7878347.0  4.0  225.095001  225.067880  221.923409   \n",
       "97  225.100006  2143996.0  4.0  224.509995  224.908127  222.016660   \n",
       "98  224.535004  3135541.0  4.0  223.255005  224.777531  222.029759   \n",
       "99  223.259903  2088312.0  4.0  222.729996  224.709197  221.967092   \n",
       "\n",
       "        rsi_30      cci_30       dx_30  close_30_sma  \n",
       "0   100.000000  -66.666667  100.000000    224.770004  \n",
       "1   100.000000  -66.666667  100.000000    224.967499  \n",
       "2   100.000000  100.000000   39.687424    225.331665  \n",
       "3    93.204041  111.308097   74.173003    225.491249  \n",
       "4    94.122327   59.383228   43.518110    225.626999  \n",
       "..         ...         ...         ...           ...  \n",
       "95   45.555309  -51.733595   18.916673    223.970272  \n",
       "96   56.544824   68.170619   26.439006    224.011929  \n",
       "97   52.137385   48.290240   25.920321    224.029717  \n",
       "98   44.448656  -30.995119    3.810734    224.003003  \n",
       "99   41.782129  -77.623543    9.784003    223.960569  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958\n",
      "2100\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train_data.csv')\n",
    "# trade.to_csv('trade_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import INDICATORS, TRAINED_MODEL_DIR\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "\n",
    "from stable_baselines3.common.logger import configure\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "\n",
    "RESULTS_DIR = 'results'\n",
    "TRAINED_MODEL_DIR = 'trained models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 9\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS_15M)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS_15M,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1\n",
    "}\n",
    "\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = False\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1654      |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.41     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -6.05e-10 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 6.88e-16  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1732     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.44    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 3.25e-09 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 9.44e-18 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1806     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.65e-09 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.2e-18  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1838      |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.52     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -3.95e-09 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.24e-17  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1875     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.55    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.67e-09 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 1.13e-18 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1911     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.61    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 2.66e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.21     |\n",
      "|    value_loss         | 3.33e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1939     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.67    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 2.2e-10  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.28     |\n",
      "|    value_loss         | 3.33e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1955     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.71    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 1.76e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.34     |\n",
      "|    value_loss         | 1.8e-16  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1968     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.46e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.42     |\n",
      "|    value_loss         | 7.89e-17 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1961     |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.83    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -1.1e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.51     |\n",
      "|    value_loss         | 3.7e-21  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1972      |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -1.64e-09 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.57      |\n",
      "|    value_loss         | 4.48e-19  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1977     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 8.38e-09 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 2.19e-17 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1984      |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -2.35e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.69      |\n",
      "|    value_loss         | 1.93e-17  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1991     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 4.4e-09  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 2.47e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1998     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 4.36e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 5.92e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1998     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 3.45e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 4.53e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1996     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2.32e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.96     |\n",
      "|    value_loss         | 2.31e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 2000     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 5.56e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2        |\n",
      "|    value_loss         | 9.25e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 2006     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.14    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 6.9e-10  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.07     |\n",
      "|    value_loss         | 9.25e-20 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 2008     |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.19    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 2.56e-07 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.17     |\n",
      "|    value_loss         | 1.73e-14 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1998     |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 4.78e-07 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.3      |\n",
      "|    value_loss         | 4.8e-14  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1991     |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.0706   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.43     |\n",
      "|    value_loss         | 0.0017   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1993     |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.00673  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.5      |\n",
      "|    value_loss         | 6.18e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1988      |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.36     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -8.98e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 2.57      |\n",
      "|    value_loss         | 6.42e-16  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1991     |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.4     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 2.87e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.66     |\n",
      "|    value_loss         | 1.92e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1994     |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.44    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 2.66e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.77     |\n",
      "|    value_loss         | 2.15e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1994     |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.47    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 2.89e-09 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 2.86     |\n",
      "|    value_loss         | 1.96e-18 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1994      |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.49     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -5.43e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 2.92      |\n",
      "|    value_loss         | 3.52e-16  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1993      |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -2.79e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 3.04      |\n",
      "|    value_loss         | 4.54e-17  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1994     |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.56    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 3.27e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.14     |\n",
      "|    value_loss         | 1.21e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1998     |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.6     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 2.76e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.25     |\n",
      "|    value_loss         | 4.62e-17 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1986     |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.54e-10 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.42     |\n",
      "|    value_loss         | 3.7e-21  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1980     |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 3.81e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.56     |\n",
      "|    value_loss         | 1.1e-16  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1979     |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.73    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.00769  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.71     |\n",
      "|    value_loss         | 8.71e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1976     |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.74    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.000562 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 3.76     |\n",
      "|    value_loss         | 7.33e-08 |\n",
      "------------------------------------\n",
      "day: 1957, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999840.95\n",
      "total_reward: -159.05\n",
      "total_cost: 159.05\n",
      "total_trades: 10\n",
      "Sharpe: -0.987\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1975      |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.78     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -6.39e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 3.88      |\n",
      "|    value_loss         | 1.91e-16  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1960     |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.81    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 3.02e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.03     |\n",
      "|    value_loss         | 6.74e-17 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1960     |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 2.82e-06 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.19     |\n",
      "|    value_loss         | 8.93e-13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1957     |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.00219  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.29     |\n",
      "|    value_loss         | 6.38e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1958     |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.91    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 9.48e-06 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.43     |\n",
      "|    value_loss         | 1.69e-11 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1954     |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.000777 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.54     |\n",
      "|    value_loss         | 1.06e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1956      |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 6.41e-08  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 4.67      |\n",
      "|    value_loss         | 4.18e-16  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1957     |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 1.01e-07 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.86     |\n",
      "|    value_loss         | 4.02e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1955     |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 9.74e-06 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 4.91     |\n",
      "|    value_loss         | 1.53e-11 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1958     |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.00994  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.02     |\n",
      "|    value_loss         | 9.98e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1959      |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 9.86e-08  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 5.19      |\n",
      "|    value_loss         | 1.71e-16  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1960      |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.11     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 1e-07     |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 5.44      |\n",
      "|    value_loss         | 9.83e-16  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1954     |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.000291 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.53     |\n",
      "|    value_loss         | 1.31e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1950      |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.16     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 1.37e-07  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 5.69      |\n",
      "|    value_loss         | 6.89e-16  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1943     |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 3.29e-07 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.91     |\n",
      "|    value_loss         | 1.47e-14 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1939     |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.00304 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.95     |\n",
      "|    value_loss         | 1.23e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1942     |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.0109   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.98     |\n",
      "|    value_loss         | 1.38e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1944     |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 0.00177  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.99     |\n",
      "|    value_loss         | 4.05e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1948     |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.00272  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.06     |\n",
      "|    value_loss         | 1.09e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1950      |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -0.000678 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 6.13      |\n",
      "|    value_loss         | 4.94e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1952     |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 0.000579 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.24     |\n",
      "|    value_loss         | 4.44e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1954     |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.27    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.000427 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.37     |\n",
      "|    value_loss         | 2.16e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1957     |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 9.03e-09 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.49     |\n",
      "|    value_loss         | 1.23e-16 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1959      |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.31     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -1.78e-07 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 6.65      |\n",
      "|    value_loss         | 1.85e-15  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1961     |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 2.25e-06 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.7      |\n",
      "|    value_loss         | 5.96e-13 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1962     |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.34    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 1.34e-07 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.86     |\n",
      "|    value_loss         | 4.3e-16  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1956     |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.36    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.000699 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 6.96     |\n",
      "|    value_loss         | 4.29e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1951     |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.38    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.000563 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 7.12     |\n",
      "|    value_loss         | 3.82e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1941      |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.4      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 0.00614   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 7.27      |\n",
      "|    value_loss         | 4.26e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1941     |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | 0.0247   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 7.42     |\n",
      "|    value_loss         | 8.45e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1942      |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.44     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 6.17e-06  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 7.56      |\n",
      "|    value_loss         | 4.23e-12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1944      |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.47     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -1.01e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 7.79      |\n",
      "|    value_loss         | 1.04e-17  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1946     |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 3.67e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.14     |\n",
      "|    value_loss         | 1.12e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1948     |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.56    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 0.000142 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.49     |\n",
      "|    value_loss         | 1.95e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1948     |\n",
      "|    iterations         | 7000     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6999     |\n",
      "|    policy_loss        | 0.0055   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.6      |\n",
      "|    value_loss         | 3.1e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1946      |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -3.12e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 8.82      |\n",
      "|    value_loss         | 9.67e-17  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1947     |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.61    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.0355   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 8.9      |\n",
      "|    value_loss         | 0.000124 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1944     |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.000676 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 9.07     |\n",
      "|    value_loss         | 5.13e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1941     |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.65    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 0.0247   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 9.3      |\n",
      "|    value_loss         | 5.34e-05 |\n",
      "------------------------------------\n",
      "day: 1957, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999704.28\n",
      "total_reward: -295.72\n",
      "total_cost: 296.03\n",
      "total_trades: 16\n",
      "Sharpe: -1.290\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1942     |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | 0.0126   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 9.57     |\n",
      "|    value_loss         | 1.81e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1943     |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.7     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.00986  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 9.75     |\n",
      "|    value_loss         | 9.8e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1945      |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.71     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 0.00424   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 9.88      |\n",
      "|    value_loss         | 1.8e-06   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1947      |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.73     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 0.00133   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 10.1      |\n",
      "|    value_loss         | 1.53e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1946     |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 39500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.00214  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.2     |\n",
      "|    value_loss         | 3e-07    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1947     |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.76    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -84      |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.3     |\n",
      "|    value_loss         | 552      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1948     |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.77    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | 9.27e-05 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.5     |\n",
      "|    value_loss         | 7.49e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1950     |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 7.69e-08 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.6     |\n",
      "|    value_loss         | 1.01e-16 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1951     |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.00519  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 10.9     |\n",
      "|    value_loss         | 1.54e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1952     |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.82    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | 0.00307  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11       |\n",
      "|    value_loss         | 8.21e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1953      |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.84     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 0.0123    |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 11.2      |\n",
      "|    value_loss         | 1.39e-05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1954     |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.00811 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.3     |\n",
      "|    value_loss         | 6.9e-06  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1955      |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.86     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 0.00648   |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 11.5      |\n",
      "|    value_loss         | 3.51e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1957     |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.00802  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.6     |\n",
      "|    value_loss         | 4.31e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1952     |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.88    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.0199   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.7     |\n",
      "|    value_loss         | 3.58e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1940     |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.023    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.8     |\n",
      "|    value_loss         | 4.9e-05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1941     |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 0.0129   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.9     |\n",
      "|    value_loss         | 1.38e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1937     |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 3.26e-05 |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 12.2     |\n",
      "|    value_loss         | 9.62e-11 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1938     |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.0292   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 12.5     |\n",
      "|    value_loss         | 8.32e-05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1938      |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.98     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 3.29e-06  |\n",
      "|    reward             | -97.01854 |\n",
      "|    std                | 12.9      |\n",
      "|    value_loss         | 1.07e-12  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1940     |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.98    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.0026   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 13       |\n",
      "|    value_loss         | 5.53e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1940     |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.99    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.00534  |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 13.1     |\n",
      "|    value_loss         | 2.28e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 1939     |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 3e-06    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 13.3     |\n",
      "|    value_loss         | 7.92e-13 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1935      |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -0.000485 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 13.5      |\n",
      "|    value_loss         | 2.05e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1935      |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -1.02e-08 |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 14        |\n",
      "|    value_loss         | 2.58e-16  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 1936      |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.08     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 0.000425  |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 14.3      |\n",
      "|    value_loss         | 1.31e-08  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "if if_using_a2c:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_a2c.set_logger(new_logger_a2c)\n",
    "  \n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name='a2c',\n",
    "                                    total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 1957, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 172       |\n",
      "|    time_elapsed    | 45        |\n",
      "|    total_timesteps | 7832      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.28e+04 |\n",
      "|    critic_loss     | 1.72e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 7731      |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 203       |\n",
      "|    time_elapsed    | 77        |\n",
      "|    total_timesteps | 15664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -9.49e+03 |\n",
      "|    critic_loss     | 7.3e+05   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15563     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 216       |\n",
      "|    time_elapsed    | 108       |\n",
      "|    total_timesteps | 23496     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -5.66e+03 |\n",
      "|    critic_loss     | 9.6e+03   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 23395     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 1957, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 225       |\n",
      "|    time_elapsed    | 139       |\n",
      "|    total_timesteps | 31328     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -5.11e+03 |\n",
      "|    critic_loss     | 758       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 31227     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 225       |\n",
      "|    time_elapsed    | 173       |\n",
      "|    total_timesteps | 39160     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.19e+03 |\n",
      "|    critic_loss     | 35.4      |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 39059     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 1957, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 226       |\n",
      "|    time_elapsed    | 207       |\n",
      "|    total_timesteps | 46992     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.09e+03 |\n",
      "|    critic_loss     | 450       |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 46891     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ddpg_params(trial:optuna.Trial):\n",
    "  # Size of the replay buffer\n",
    "  buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
    "  learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2, 1e-3)\n",
    "  batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "  \n",
    "  return {\"buffer_size\": buffer_size,\n",
    "          \"learning_rate\":learning_rate,\n",
    "          \"batch_size\":batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ddpg_params_all(trial:optuna.Trial,\n",
    "                           # fixed values from previous study\n",
    "                           learning_rate=0.0103,\n",
    "                           batch_size=128,\n",
    "                           buffer_size=int(1e6)):\n",
    "\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.94, 0.96, 0.98])\n",
    "    # Polyak coeff\n",
    "    tau = trial.suggest_categorical(\"tau\", [0.08, 0.1, 0.12])\n",
    "\n",
    "    train_freq = trial.suggest_categorical(\"train_freq\", [512,768,1024])\n",
    "    gradient_steps = train_freq\n",
    "    \n",
    "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
    "    noise_std = trial.suggest_categorical(\"noise_std\", [.1,.2,.3] )\n",
    "\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"big\"])\n",
    "    # activation_fn = trial.suggest_categorical('activation_fn', [nn.Tanh, nn.ReLU, nn.ELU, nn.LeakyReLU])\n",
    "\n",
    "    net_arch = {\n",
    "        \"small\": [64, 64],\n",
    "        \"medium\": [256, 256],\n",
    "        \"big\": [512, 512],\n",
    "    }[net_arch]\n",
    "  \n",
    "    hyperparams = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"buffer_size\": buffer_size,\n",
    "        \"gamma\": gamma,\n",
    "        \"gradient_steps\": gradient_steps,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"tau\": tau,\n",
    "        \"train_freq\": train_freq,\n",
    "        #\"noise_std\": noise_std,\n",
    "        #\"noise_type\": noise_type,\n",
    "        \n",
    "        \"policy_kwargs\": dict(net_arch=net_arch)\n",
    "    }\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 9\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2 * stock_dimension + len(INDICATORS_15M) * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS_15M,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_df_for_mvo(df):\n",
    "#   return df.pivot(index=\"date\", columns=\"tic\", values=\"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def StockReturnsComputing(StockPrice, Rows, Columns): \n",
    "#   StockReturn = np.zeros([Rows-1, Columns]) \n",
    "#   for j in range(Columns):        # j: Assets \n",
    "#     for i in range(Rows-1):     # i: Daily Prices \n",
    "#       StockReturn[i,j]=((StockPrice[i+1, j]-StockPrice[i,j])/StockPrice[i,j])* 100 \n",
    "      \n",
    "#   return StockReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #compute asset returns\n",
    "# arStockPrices = np.asarray(StockData)\n",
    "# [Rows, Cols]=arStockPrices.shape\n",
    "# arReturns = StockReturnsComputing(arStockPrices, Rows, Cols)\n",
    "\n",
    "# #compute mean returns and variance covariance matrix of returns\n",
    "# meanReturns = np.mean(arReturns, axis = 0)\n",
    "# covReturns = np.cov(arReturns, rowvar=False)\n",
    " \n",
    "# #set precision for printing results\n",
    "# np.set_printoptions(precision=3, suppress = True)\n",
    "\n",
    "# #display mean returns and variance-covariance matrix of returns\n",
    "# print('Mean returns of assets in k-portfolio 1\\n', meanReturns)\n",
    "# print('Variance-Covariance matrix of returns\\n', covReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "# ef_mean = EfficientFrontier(meanReturns, covReturns, weight_bounds=(0, 0.5))\n",
    "# raw_weights_mean = ef_mean.max_sharpe()\n",
    "# cleaned_weights_mean = ef_mean.clean_weights()\n",
    "# mvo_weights = np.array([1000000 * cleaned_weights_mean[i] for i in range(len(cleaned_weights_mean))])\n",
    "# mvo_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LastPrice = np.array([1/p for p in StockData.tail(1).to_numpy()[0]])\n",
    "# Initial_Portfolio = np.multiply(mvo_weights, LastPrice)\n",
    "# Initial_Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio_Assets = TradeData @ Initial_Portfolio\n",
    "# MVO_result = pd.DataFrame(Portfolio_Assets, columns=[\"Mean Var\"])\n",
    "# MVO_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dji = YahooDownloader(\n",
    "#     start_date=TRADE_START_DATE, end_date=TRADE_END_DATE, ticker_list=[\"dji\"]\n",
    "# ).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dji = df_dji[[\"date\", \"close\"]]\n",
    "# fst_day = df_dji[\"close\"][0]\n",
    "# dji = pd.merge(\n",
    "#     df_dji[\"date\"],\n",
    "#     df_dji[\"close\"].div(fst_day).mul(1000000),\n",
    "#     how=\"outer\",\n",
    "#     left_index=True,\n",
    "#     right_index=True,\n",
    "# ).set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_a2c = (\n",
    "    df_account_value_a2c.set_index(df_account_value_a2c.columns[0])\n",
    "    if if_using_a2c\n",
    "    else None\n",
    ")\n",
    "df_result_ddpg = (\n",
    "    df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0])\n",
    "    if if_using_ddpg\n",
    "    else None\n",
    ")\n",
    "# df_result_ppo = (\n",
    "#     df_account_value_ppo.set_index(df_account_value_ppo.columns[0])\n",
    "#     if if_using_ppo\n",
    "#     else None\n",
    "# )\n",
    "# df_result_td3 = (\n",
    "#     df_account_value_td3.set_index(df_account_value_td3.columns[0])\n",
    "#     if if_using_td3\n",
    "#     else None\n",
    "# )\n",
    "# df_result_sac = (\n",
    "#     df_account_value_sac.set_index(df_account_value_sac.columns[0])\n",
    "#     if if_using_sac\n",
    "#     else None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(\n",
    "    {\n",
    "        # \"a2c\": df_result_a2c[\"account_value\"] if if_using_a2c else None,\n",
    "        \"ddpg\": df_result_ddpg[\"account_value\"] if if_using_ddpg else None,\n",
    "        \"market_price\": trade[\"close\"].div(trade[\"close\"][0]).mul(1000000),\n",
    "        # \"ppo\": df_result_ppo[\"account_value\"] if if_using_ppo else None,\n",
    "        # \"td3\": df_result_td3[\"account_value\"] if if_using_td3 else None,\n",
    "        # \"sac\": df_result_sac[\"account_value\"] if if_using_sac else None,\n",
    "        # \"mvo\": MVO_result[\"Mean Var\"],\n",
    "        # \"dji\": dji[\"close\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-02-14 00:00:00+00:00    1000000.0\n",
       "2025-02-14 00:15:00+00:00    1000000.0\n",
       "2025-02-14 00:30:00+00:00    1000000.0\n",
       "2025-02-14 00:45:00+00:00    1000000.0\n",
       "2025-02-14 01:00:00+00:00    1000000.0\n",
       "                               ...    \n",
       "2025-03-07 19:45:00+00:00    1000000.0\n",
       "2025-03-07 20:00:00+00:00    1000000.0\n",
       "2025-03-07 20:15:00+00:00    1000000.0\n",
       "2025-03-07 20:30:00+00:00    1000000.0\n",
       "2025-03-07 20:45:00+00:00    1000000.0\n",
       "Name: account_value, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_ddpg[\"account_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1000000.000000\n",
       "1       1000000.000000\n",
       "2       1000000.000000\n",
       "3       1000000.000000\n",
       "4       1000000.000000\n",
       "             ...      \n",
       "2095     990476.966665\n",
       "2096     987827.085171\n",
       "2097     988785.181942\n",
       "2098     987813.817758\n",
       "2099     989855.925369\n",
       "Name: close, Length: 2100, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade[\"close\"].div(trade[\"close\"][0]).mul(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ddpg</th>\n",
       "      <th>market_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-02-14 00:00:00+00:00</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 00:15:00+00:00</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 00:30:00+00:00</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 00:45:00+00:00</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 01:00:00+00:00</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>NaN</td>\n",
       "      <td>990476.966665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>NaN</td>\n",
       "      <td>987827.085171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>NaN</td>\n",
       "      <td>988785.181942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>987813.817758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>NaN</td>\n",
       "      <td>989855.925369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ddpg   market_price\n",
       "2025-02-14 00:00:00+00:00  1000000.0            NaN\n",
       "2025-02-14 00:15:00+00:00  1000000.0            NaN\n",
       "2025-02-14 00:30:00+00:00  1000000.0            NaN\n",
       "2025-02-14 00:45:00+00:00  1000000.0            NaN\n",
       "2025-02-14 01:00:00+00:00  1000000.0            NaN\n",
       "...                              ...            ...\n",
       "2095                             NaN  990476.966665\n",
       "2096                             NaN  987827.085171\n",
       "2097                             NaN  988785.181942\n",
       "2098                             NaN  987813.817758\n",
       "2099                             NaN  989855.925369\n",
       "\n",
       "[4200 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cumulative Return (累计收益率)\n",
    "def cumulative_return(final_value, initial_capital):\n",
    "    return (final_value - initial_capital) / initial_capital\n",
    "\n",
    "# 2. Annualized Return (年化收益率)\n",
    "def annualized_return(final_value, initial_capital, trading_days):\n",
    "    return (final_value / initial_capital) ** (252 / trading_days) - 1\n",
    "\n",
    "# 3. Annualized Volatility (年化波动率)\n",
    "def annualized_volatility(daily_returns):\n",
    "    return np.sqrt(252) * np.std(daily_returns)\n",
    "\n",
    "# 4. Sharpe Ratio (夏普比率)\n",
    "def sharpe_ratio(annualized_return, risk_free_rate, annualized_volatility):\n",
    "    return (annualized_return - risk_free_rate) / annualized_volatility\n",
    "\n",
    "# 5. Maximum Drawdown (最大回撤)\n",
    "def max_drawdown(portfolio_values):\n",
    "    peak = portfolio_values[0]\n",
    "    max_dd = 0\n",
    "    for value in portfolio_values:\n",
    "        if value > peak:\n",
    "            peak = value\n",
    "        dd = (peak - value) / peak\n",
    "        if dd > max_dd:\n",
    "            max_dd = dd\n",
    "    return max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "plt.figure()\n",
    "result.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_aapl['close'].isna().sum())  # 检查 'close' 列中是否有缺失值\n",
    "# print(df_aapl.shape)  # 查看数据的行数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import talib\n",
    "\n",
    "# # 假设 df_aapl 已经是按 15 分钟时间间隔的数据，并且包含了 'close' 列\n",
    "\n",
    "# # 确保 'datetime' 列是正确的 datetime 格式\n",
    "# # df_aapl['datetime'] = pd.to_datetime(df_aapl['datetime'])\n",
    "\n",
    "# # 填充缺失的 close 值（如果有的话）\n",
    "# df_aapl['close'] = df_aapl['close'].fillna(method='ffill')\n",
    "\n",
    "# # 检查数据是否足够\n",
    "# if len(df_aapl) < 26:\n",
    "#     print(\"数据点不足以计算 MACD 和 RSI\")\n",
    "# else:\n",
    "#     # 计算 MACD 指标\n",
    "#     df_aapl['macd'], df_aapl['macd_signal'], df_aapl['macd_hist'] = talib.MACD(\n",
    "#         df_aapl['close'], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "#     )\n",
    "\n",
    "#     # 计算 RSI 指标\n",
    "#     df_aapl['rsi'] = talib.RSI(df_aapl['close'], timeperiod=14)\n",
    "\n",
    "#     # 打印计算后的数据\n",
    "#     print(df_aapl.head())\n",
    "#     print(df_aapl.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_aapl = df_aapl.dropna(subset=['macd', 'macd_signal', 'macd_hist', 'rsi'])\n",
    "# df_aapl = df_aapl.reset_index(drop=True)\n",
    "# print(df_aapl.head(15))\n",
    "# print(df_aapl.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_date = '2025-02-25 16:15:00+00:0'\n",
    "# train = df_aapl[df_aapl['date'] < split_date].reset_index(drop=True)\n",
    "# trade = df_aapl[df_aapl['date'] >= split_date].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv('train_data.csv')\n",
    "# trade.to_csv('trade_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
